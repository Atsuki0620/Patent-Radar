# 要件定義書 v2：注目特許仕分けくん - HIT見逃し防止・データパイプライン拡張

## 1. 改訂概要

**v1からの主要変更点:**
- **改良**: HIT見逃しリスク最小化のための召回率重視設計
- **拡張**: Excel特許一覧からJSONL変換の自動化パイプライン追加

**背景:**
- v1テスト結果: False Negative 5件（20%のHIT特許見逃し）が発生
- ランキング品質: HITの平均ランク30.2位と改善余地あり  
- 実運用での特許データ準備の自動化要求

## 2. ゴールと前提（v2更新）

### 2.1 主要ゴール
1. **HIT見逃し最小化**: False Negativeを限りなくゼロに近づける
2. **データ準備自動化**: Excel特許リスト→JSONL変換の完全自動化
3. **運用効率向上**: データ準備から分析まで一貫したワークフロー

### 2.2 前提条件
- v1のMVP機能（二値判定、LLM_confidenceランキング）を基盤として拡張
- HIT見逃しによる機会損失リスクを最重要視
- False Positiveは後続の人的確認で対処可能（許容レベル内）

## 3. HIT見逃し防止戦略（新規）

### 3.1 召回率優先アプローチ

#### 3.1.1 多段階判定システム
```yaml
判定フロー:
  第1段階: 通常判定（既存）
  第2段階: 低信頼度MISS（<0.7）の再評価
  第3段階: borderline判定での保守的HIT判定
```

#### 3.1.2 信頼度閾値最適化
- **HIT閾値**: 0.5→0.3に下げて見逃し防止
- **再評価閾値**: MISS予測信頼度<0.7で自動再判定
- **アラート機能**: 境界ケース（0.3-0.7）の人的確認推奨

#### 3.1.3 プロンプト強化
```
改良プロンプト要素:
- HIT検出重視の指示追加
- 技術的関連性の拡大解釈指示
- 見逃しリスクに対する警告
- 保守的判定の推奨
```

### 3.2 アンサンブル判定（段階実装）

#### Phase1: デュアル判定
- 異なるプロンプトでの2回判定
- 1つでもHITなら最終HIT判定

#### Phase2（将来拡張）: 多モデル判定
- 複数LLMモデルでの並行判定
- 投票システムによる最終決定

## 4. Excel→JSONL変換パイプライン（新規）

### 4.1 Excel入力仕様

#### 4.1.1 標準フォーマット
| 列名 | 必須 | データ型 | 説明 |
|------|------|----------|------|
| publication_number | ✅ | 文字列 | 公開番号（JP2025-123456A） |
| title | ✅ | 文字列 | 発明名称 |
| assignee | ✅ | 文字列 | 出願人・権利者 |
| pub_date | ✅ | 日付 | 公開日（YYYY-MM-DD） |
| abstract | ✅ | 文字列 | 抄録 |
| claim_1 | ✅ | 文字列 | 独立請求項1 |
| ipc | ⚪ | 文字列 | IPC分類（;区切り） |
| cpc | ⚪ | 文字列 | CPC分類（;区切り） |
| legal_status | ⚪ | 文字列 | 法的状態 |
| citations_forward | ⚪ | 数値 | 被引用回数 |
| url_hint | ⚪ | 文字列 | 特許詳細URL |

#### 4.1.2 データ品質要件
- **必須フィールド**: 空白・NULL不可
- **日付形式**: ISO8601（YYYY-MM-DD）
- **公開番号形式**: 国コード+年+連番+種別（JP2025-123456A）
- **テキスト文字数制限**: title≤200文字、abstract≤1000文字

### 4.2 変換パイプライン

#### 4.2.1 処理フロー
```
Excel読み込み → データ検証 → 正規化 → Claims構造化 → JSONL出力
```

#### 4.2.2 データ検証機能
- **必須フィールドチェック**: 欠損データの検出・レポート
- **形式検証**: 日付、公開番号、URL形式の妥当性確認
- **重複検出**: publication_numberの重複チェック
- **文字数制限**: フィールド長の制限チェック

#### 4.2.3 Claims構造化
```python
# Excelの平面データから構造化
claim_1_text -> {
    "no": 1,
    "text": "...",
    "is_independent": true
}
```

#### 4.2.4 エラーハンドリング
- **データ品質レポート**: 問題データの詳細リスト出力
- **部分変換**: 有効データのみでJSONL生成継続
- **補完機能**: 一部フィールドの自動補完（assignee等）

### 4.3 出力JSONL仕様（拡張）
```json
{
  "publication_number": "JP2025-123456A",
  "title": "...",
  "assignee": "...",
  "pub_date": "2025-03-15",
  "claims": [
    {
      "no": 1,
      "text": "...",
      "is_independent": true
    }
  ],
  "abstract": "...",
  "ipc": ["B01D61/00", "G06N20/00"],
  "cpc": ["B01D61/025", "G06N20/10"],
  "legal_status": "pending",
  "citations_forward": 5,
  "url_hint": "https://...",
  "data_source": "excel_conversion",
  "conversion_timestamp": "2025-08-23T23:45:20Z",
  "quality_flags": {
    "complete_data": true,
    "auto_completed_fields": ["assignee"],
    "validation_warnings": []
  }
}
```

## 5. 拡張システム構成

### 5.1 新ディレクトリ構成
```
project-root/
├─ src/
│  ├─ data_preparation/          # 新規追加
│  │  ├─ __init__.py
│  │  ├─ excel_parser.py         # Excel読み込み・パース
│  │  ├─ data_validator.py       # データ検証・品質チェック
│  │  ├─ data_normalizer.py      # データ正規化・補完
│  │  └─ jsonl_generator.py      # JSONL形式での出力
│  ├─ core/
│  │  ├─ normalize.py            # 強化: Excel変換データ対応
│  │  ├─ extract.py
│  │  ├─ export.py
│  │  └─ screener.py             # 強化: 多段階判定対応
│  ├─ llm/
│  │  ├─ client.py
│  │  ├─ prompts.py              # 強化: HIT重視プロンプト
│  │  └─ pipeline.py             # 強化: 再判定機能
│  ├─ ranking/
│  │  └─ sorter.py               # 強化: 召回率重視ランキング
│  └─ quality/                   # 新規追加
│     ├─ __init__.py
│     ├─ hit_validator.py        # HIT判定の妥当性検証
│     └─ recall_optimizer.py     # 召回率最適化
├─ data/
│  ├─ input/                     # 新規追加
│  │  └─ excel_templates/        # Excel入力テンプレート
│  └─ processed/                 # 新規追加
│     └─ conversion_logs/        # 変換ログ・品質レポート
├─ tests/
│  ├─ data_preparation/          # 新規追加
│  │  ├─ test_excel_parser.py
│  │  ├─ test_data_validator.py
│  │  └─ test_jsonl_generator.py
│  └─ quality/                   # 新規追加
│     └─ test_recall_optimizer.py
└─ workflows/                    # 新規追加
   ├─ data_preparation.py        # Excel→JSONL一括処理
   └─ high_recall_screening.py   # 召回率重視スクリーニング
```

### 5.2 処理パイプライン（拡張）

#### 段階1: データ準備（新規）
1. Excel特許リスト読み込み
2. データ検証・品質チェック
3. 正規化・補完処理
4. JSONL形式での出力
5. 品質レポート生成

#### 段階2: スクリーニング（改良）
1. JSONL読み込み・正規化（既存）
2. 請求項・抄録抽出（既存）
3. LLM要旨化（既存）
4. **多段階判定**（新規）:
   - 第1判定: 通常プロンプト
   - 第2判定: 低信頼MISS再評価
   - 第3判定: 境界ケース保守判定
5. **召回率重視ランキング**（改良）
6. CSV/JSONL出力（既存）

## 6. 設定（v2拡張）

### 6.1 召回率重視設定
```yaml
recall_optimization:
  enabled: true
  hit_threshold: 0.3              # HIT判定の最低閾値（下げて見逃し防止）
  miss_reeval_threshold: 0.7      # MISS再評価の閾値
  conservative_mode: true         # 保守的判定モード
  dual_judgment: true             # デュアル判定の有効化

hit_detection:
  primary_prompt: "hit_focused"   # HIT重視プロンプト
  secondary_prompt: "conservative" # 保守判定用プロンプト
  ensemble_voting: "any_hit"      # どちらか1つがHITなら最終HIT

data_preparation:
  excel_input_dir: "data/input"
  jsonl_output_dir: "data/processed"
  quality_report_dir: "data/processed/conversion_logs"
  validation_strict: false        # 厳格検証モード（必須フィールドのみ）
  auto_completion: true           # 自動補完機能
  duplicate_handling: "error"     # 重複データの処理方法
```

### 6.2 既存設定の更新
```yaml
run:
  use_topk: false
  use_retrieval_score: false
  verify_quotes: false
  high_recall_mode: true          # 新規: 召回率重視モード

llm:
  model: "gpt-4o-mini"
  temperature: 0.0                # 一貫性重視
  response_format: json
  max_tokens: 400                 # 多段階判定で若干増加
  dual_judgment_enabled: true     # 新規: デュアル判定

ranking:
  method: "recall_optimized"      # 新規: 召回率最適化ランキング
  tiebreaker: "pub_number"
  hit_boost_factor: 1.2           # 新規: HIT判定の順位ブースト
```

## 7. プロンプト設計（改良）

### 7.1 HIT重視プロンプト
```
判定指示の強化ポイント:
1. HIT見逃しのリスク強調
2. 技術的関連性の広義解釈推奨  
3. 境界ケースでの保守的判定指示
4. 発明の本質的価値との関連性重視
```

### 7.2 再評価プロンプト（新規）
```
再判定用特別指示:
- 初回MISS判定の再検討
- より慎重な技術的関連性評価
- 発明効果との潜在的関連性検討
- 保守的観点での最終判定
```

## 8. 評価基準（v2更新）

### 8.1 成功基準の優先度変更
| 指標 | v1目標 | v2目標 | 優先度 |
|------|--------|--------|--------|
| **召回率（Recall）** | ≥80% | **≥95%** | **最高** |
| 精度（Precision） | ≥80% | ≥70% | 高 |
| 総合精度（Accuracy） | ≥80% | ≥75% | 中 |
| F1スコア | ≥80% | ≥80% | 高 |

### 8.2 HIT見逃し許容基準
- **False Negative許容**: 最大2件（現在5件から改善）
- **False Negative率**: ≤8%（現在20%から大幅改善）
- **境界ケース処理**: 60%以上をHITと保守判定

### 8.3 データ品質基準
- **変換成功率**: ≥95%（有効データ変換率）
- **データ完全性**: 必須フィールド100%充足
- **形式適合性**: 公開番号、日付形式100%準拠

## 9. 実装プラン（v2）

### Phase 1: データ準備パイプライン（2週間）
1. **excel_parser.py**: Excel読み込み機能
2. **data_validator.py**: データ検証・品質チェック
3. **jsonl_generator.py**: JSONL出力機能
4. **品質保証**: 変換テスト・エラーハンドリング

### Phase 2: 召回率最適化（2週間） 
5. **プロンプト改良**: HIT重視・保守判定プロンプト
6. **多段階判定**: 再評価・境界ケース処理
7. **ランキング改良**: 召回率重視ソート
8. **信頼度較正**: 閾値最適化

### Phase 3: 統合・検証（1週間）
9. **E2Eワークフロー**: Excel→分析の一貫処理
10. **品質検証**: 召回率95%目標達成確認
11. **パフォーマンス最適化**: 処理速度・メモリ効率

### Phase 4: 運用準備（1週間）
12. **ドキュメント整備**: 操作手順・トラブルシューティング
13. **テンプレート作成**: Excel入力テンプレート
14. **運用テスト**: 実データでの検証

## 10. リスク管理（v2）

### 10.1 召回率重視のトレードオフ
- **リスク**: False Positive増加による確認コスト増
- **緩和**: 信頼度による優先順位付け、段階的確認プロセス

### 10.2 データ品質リスク
- **リスク**: Excel入力データの品質バラツキ
- **緩和**: 厳格な検証機能、標準テンプレート提供、品質レポート

### 10.3 処理コスト増加
- **リスク**: 多段階判定によるLLM API呼び出し増加
- **緩和**: 再判定対象の絞り込み、バッチ処理最適化

## 11. 運用・保守（v2）

### 11.1 継続的改善プロセス
- **月次評価**: 召回率・見逃し件数の定期監視
- **プロンプト調整**: 見逃しパターン分析による改良
- **閾値最適化**: 運用データに基づく動的調整

### 11.2 品質監視
- **アラート機能**: 召回率低下時の自動通知
- **品質ダッシュボード**: リアルタイム性能監視
- **改善提案**: AI分析による自動改善案提示

## 12. 期待効果（v2）

### 12.1 HIT検出改善
- **見逃し削減**: False Negative 5件→2件（60%削減）
- **召回率向上**: 80%→95%（18.75%向上）
- **機会損失防止**: 重要特許見逃しリスクの大幅軽減

### 12.2 運用効率向上
- **データ準備自動化**: Excel→JSONL変換の完全自動化
- **品質保証**: 自動検証による入力データ品質確保
- **一貫ワークフロー**: データ準備から分析まで統合処理

### 12.3 運用コスト最適化
- **人的工数削減**: データ準備作業の90%自動化
- **品質向上**: 手作業エラー削減による再作業コスト軽減
- **スケーラビリティ**: 大量データ処理対応

---

**要件定義書 v2 - 更新履歴**
- v2.0: 2025-08-23 - HIT見逃し防止・Excel変換パイプライン追加
- v1.0: 2025-08-19 - MVP仕様策定

*注目特許仕分けくん v2: より確実で効率的な特許スクリーニングシステム*