# 要件定義書：注目特許仕分けくん

## 1. ゴールと前提

- **ゴール**：発明アイデアに対し、各JSON特許を **二値判定（hit/miss）** し、**短いヒット理由（原文の短い引用＋出典）** を付して一覧化する。
- **前提**：
  - 架空特許の **JSONL** と、模範回答（ラベル） **JSONL** が既に存在（評価用ゴールドセット）。
  - 本仕組みは初期スクリーニング用途。法的最終判断・弱点可視化はスコープ外。
  - MVPでは **TopK絞り込みなし**、**合成式は LLM\_confidence のみ**、**エビデンス検証オフ**。

## 2. スコープ

- **対象**：液体分離設備に関する発明アイデアと、先行特許JSON群の照合。
- **出力**：注目候補の抽出（hit優先）、ヒット理由の簡潔提示。
- **除外**：未カバー要素の抽出、クレームチャート作成、詳細な進歩性評価。

## 3. 入力仕様

### 3.1 発明アイデア（テキスト or JSON）

任意キー：`title, problem, solution, effects, key_elements[], constraints`

### 3.2 先行特許（1件=1JSON）

- **必須**：`publication_number, title, assignee, pub_date, claims[], abstract`
- **任意**：`description[] (id推奨), cpc, ipc, legal_status, citations_forward, url_hint`
- `claims[]`要素：`{ no: <int>, text: <string>, is_independent: <bool> }`

> 備考：評価用ゴールドセットは JSONL（1行=1特許）で提供。ラベルJSONLは `publication_number` と `gold_label` を対応付ける。

## 4. 出力仕様

### 4.1 CSV（一覧）

```
rank, pub_number, title, assignee, pub_date, decision, LLM_confidence,
hit_reason_1, hit_src_1, hit_reason_2, hit_src_2, url_hint
```

### 4.2 JSONL（詳細、1行=1特許）

```json
{
  "pub_number": "JP2025-xxxxxxA",
  "decision": "hit",
  "LLM_confidence": 0.82,
  "reasons": [
    {"quote": "差圧に基づくポンプ制御", "source": {"field": "claim", "locator": "claim 1"}},
    {"quote": "閾値を超えた場合に停止", "source": {"field": "abstract", "locator": "sent 2"}}
  ],
  "flags": {"verified": false, "used_retrieval": false, "used_topk": false}
}
```

## 5. 判定ロジック（MVP）

- **LLM使用**：
  1. 発明要旨化（短文＋キーワード）
  2. 特許要旨化（独立請求項＋抄録）
  3. 当たり/外れ二値判定：`decision (hit|miss)`, `LLM_confidence (0..1)`, `reasons (<=2)`
- **LLM非使用**：入力JSONの正規化・抽出、CSV/JSONL出力、ログ記録。
- **最終スコア**：`final_score = LLM_confidence`（同点は `pub_number` などで安定ソート）。

## 6. 処理フロー（MVP）

1. JSONロード/正規化（全半角・大小・単位など）
2. 抽出：`claim 1`（独立）＋ `abstract`（必要に応じ代表従属）
3. LLM：発明要旨化（1回）／特許要旨化（各件）
4. LLM：二値判定＋ヒット理由（引用<=12語、最大2件）
5. 並び替え：`LLM_confidence` 降順（タイブレーク固定）
6. CSV/JSONLに出力、ログ保存

## 7. ディレクトリ構成

```
project-root/
├─ docs/
│  ├─ requirements.md                # 本書
│  └─ prompts/                       # 生成プロンプト一式（既存）
├─ src/
│  ├─ core/                          # normalize, extract, export
│  ├─ llm/                           # client, prompts, pipeline
│  ├─ ranking/                       # LLM_confのみの並べ替え
│  ├─ retrieval/                     # 将来拡張（初期は未使用）
│  └─ verify/                        # 将来拡張（初期は未使用）
├─ tests/
│  ├─ data/                          # 架空特許JSONL・ラベルJSONL
│  ├─ unit/                          # 抽出/並べ替え など
│  └─ integration/                   # E2E（MVPフロー）
├─ archive/
│  ├─ logs/                          # 実行ログ
│  └─ outputs/                       # 過去のCSV/JSONL
└─ README.md
```

## 8. 設定（初期値）

```yaml
run:
  use_topk: false
  use_retrieval_score: false
  verify_quotes: false
llm:
  temperature: 0.0
  response_format: json
  max_tokens: 320
ranking:
  method: "llm_only"  # final = LLM_confidence
io:
  out_csv: outputs/attention_patents.csv
  out_jsonl: outputs/details.jsonl
```

## 9. 評価（MVP）

- **正解照合**：ラベルJSONL（hit/borderline/miss）を参照。
  - システム出力は hit/miss のみ。`borderline` は**要精査**として運用上ヒトレビュー対象。
- **指標**：Precision\@TopN、Recall\@TopN、並びの安定性（同点処理）。

## 10. 将来拡張（参考：必要時のみ実装）

> いずれも **意味ベース** を採用し、キーワード偏重手法（例：BM25）は用いない。

- **TopK絞り込み**：件数増大時に、意味的関連度で上位候補へ圧縮（MVP未実装）。
- **エビデンス検証**：ヒット理由の引用が実際に該当範囲に存在するかを機械照合（MVP未実装）。
- **retrieval\_score追加**：意味的近さの補助スコアを `final_score` に加算し順位安定化（MVP未実装）。

## 11. 受け入れ基準

- 全件に `decision` と `LLM_confidence`、最大2件の `reasons` が付与されている。
- CSV/JSONLのカラム・キーが本要件に一致。
- 再実行で並び順が安定（同点のタイブレーク規則が機能）。

## 12. リスクと緩和

- **誤ヒット混入**：将来、エビデンス検証をオン。
- **順位の納得感不足**：将来、retrieval\_scoreを追加。
- **件数増によるコスト増**：将来、TopKを導入。

## 13. 開発プラン（更新日時: 2025-08-19）

### TDD & Code Reviewアプローチでの実装

#### Phase 1: 環境セットアップ
1. 仮想環境の依存関係インストール（pip install -r requirements.txt）
2. .env設定とOpenAI API key設定確認

#### Phase 2: コア機能実装（改良されたTDD+Code Review）
3. **normalize.py（JSONデータ正規化）** ✅完了
   - Phase A: テスト設計 → code-reviewer設計レビュー → テスト実装 → 初回pytest(Red)
   - Phase B: 実装 → pytest(Green) → code-reviewer実装レビュー → リファクタリング → 最終pytest
4. **extract.py（請求項・抄録抽出）** ✅完了
   - Phase A: テスト設計 → code-reviewer設計レビュー → テスト実装 → 初回pytest(Red)
   - Phase B: 実装 → pytest(Green) → code-reviewer実装レビュー → リファクタリング → 最終pytest
5. **export.py（CSV/JSONL出力）** 
   - Phase A,B同様のフローで実装予定

#### Phase 3: LLM機能実装（TDD）
6. **client.py（OpenAI APIクライアント）**
   - `tests/unit/test_client.py` 作成 → pytest実行
   - `src/llm/client.py` 実装 → pytest実行 → code-reviewer
7. **prompts.py（プロンプトテンプレート）**
   - `tests/unit/test_prompts.py` 作成 → pytest実行
   - `src/llm/prompts.py` 実装 → pytest実行 → code-reviewer
8. **pipeline.py（LLM処理パイプライン）**
   - `tests/unit/test_pipeline.py` 作成 → pytest実行
   - `src/llm/pipeline.py` 実装 → pytest実行 → code-reviewer

#### Phase 4: ランキング機能実装（TDD）
9. **sorter.py（LLM_confidence基準ソート）**
   - `tests/unit/test_sorter.py` 作成 → pytest実行
   - `src/ranking/sorter.py` 実装 → pytest実行 → code-reviewer

#### Phase 5: メインアプリケーション（TDD）
10. **統合実装**
    - `tests/unit/test_screener.py` 作成 → pytest実行
    - `src/core/screener.py` 実装 → pytest実行 → code-reviewer
    - `tests/integration/test_e2e.py` 作成 → pytest実行
    - `src/main.py` 実装 → pytest実行 → code-reviewer

#### Phase 6: 品質保証
11. 全テスト実行（pytest --cov=src）
12. 統合テストで実際のテストデータ使用
13. 最終code-reviewでセキュリティ・パフォーマンス確認

### 実装方針
- 各機能実装前にテストケース作成
- 実装後は必ずpytest実行で動作確認
- コード完成時はcode-reviewerで品質チェック
- 継続的にテストが通る状態を維持
- 早期バグ発見・修正でコード品質向上
- config.yamlの設定値に準拠した実装

### 実装状況（更新日時: 2025-08-19）

#### 完了済み
- **Phase 1**: 環境セットアップ（完了）
- **Phase 2**: コア機能実装
  - normalize.py（完了） - セキュリティ・パフォーマンス強化済み
  - extract.py（完了） - code-reviewer指摘事項を反映したリファクタリング済み

#### 新しい開発フロー導入
**従来**: テスト作成 → 実装 → pytest → code-reviewer
**改良版**: 
- **Phase A**: テスト設計 → code-reviewer設計レビュー → テスト改善 → 初回pytest(Red)
- **Phase B**: 実装 → pytest(Green) → code-reviewer実装レビュー → リファクタリング → 最終pytest

#### 品質改善項目（extract.pyで実施済み）
- **セキュリティ**: ReDoS攻撃対策、パストラバーサル防止、入力検証強化
- **パフォーマンス**: 設定キャッシュ、事前コンパイル済み正規表現、メモリ効率化
- **保守性**: 定数クラス化、関数分割、エラーハンドリング改善

#### 次回実装予定
- export.py（CSV/JSONL出力）
- sorter.py（LLM_confidenceソート）

