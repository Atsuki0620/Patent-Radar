#!/usr/bin/env python3
"""
çµ±åˆç‰¹è¨±åˆ†æã‚·ã‚¹ãƒ†ãƒ 
äºŒå€¤åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ (HIT/MISS)ã«ç‰¹åŒ–ã—ãŸç°¡ç´ åŒ–åˆ†æ
- äºŒå€¤åˆ†é¡æ··åŒè¡Œåˆ—
- å®Ÿç”¨æ€§æŒ‡æ¨™ 
- BORDERLINEã‚±ãƒ¼ã‚¹åˆ†æ
- HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime

class PatentAnalysis:
    """çµ±åˆç‰¹è¨±åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.predictions = []
        self.gold_labels = {}
        self.analysis_results = {}
        
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        print("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        
        predictions_path = Path("archive/outputs/goldset_results.jsonl")
        with open(predictions_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    self.predictions.append(json.loads(line))
        
        labels_path = Path("testing/data/labels.jsonl")
        with open(labels_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line:
                    label_data = json.loads(line)
                    self.gold_labels[label_data['publication_number']] = label_data
        
        print(f"äºˆæ¸¬çµæœ: {len(self.predictions)}ä»¶")
        print(f"ã‚´ãƒ¼ãƒ«ãƒ‰ãƒ©ãƒ™ãƒ«: {len(self.gold_labels)}ä»¶")
    
    def prepare_analysis_data(self):
        """åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿æº–å‚™"""
        matched_pairs = []
        
        for pred in self.predictions:
            pub_num = pred['publication_number']
            if pub_num in self.gold_labels:
                gold_label = self.gold_labels[pub_num]['gold_label']
                pred_decision = pred.get('decision', 'miss')
                confidence = pred.get('confidence', 0.0)
                
                matched_pairs.append({
                    'pub_number': pub_num,
                    'gold_label': gold_label,
                    'pred_label': pred_decision,
                    'confidence': confidence,
                    'title': pred.get('title', ''),
                    'pred_data': pred,
                    'gold_data': self.gold_labels[pub_num]
                })
        
        return matched_pairs
    
    def calculate_binary_metrics(self, matched_pairs):
        """äºŒå€¤åˆ†é¡æŒ‡æ¨™è¨ˆç®—"""
        print("\näºŒå€¤åˆ†é¡æŒ‡æ¨™è¨ˆç®—ä¸­...")
        
        tp = tn = fp = fn = 0
        borderline_cases = []
        borderline_hit_pred = borderline_miss_pred = 0
        
        for pair in matched_pairs:
            gold = pair['gold_label']
            pred = pair['pred_label']
            
            if gold == 'borderline':
                borderline_cases.append(pair)
                if pred == 'hit':
                    borderline_hit_pred += 1
                else:
                    borderline_miss_pred += 1
            elif gold == 'hit':
                tp += 1 if pred == 'hit' else (fn := fn + 1)
            elif gold == 'miss':
                fp += 1 if pred == 'hit' else (tn := tn + 1)
        
        total_clear = tp + tn + fp + fn
        accuracy = (tp + tn) / total_clear if total_clear > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        self.analysis_results['binary_metrics'] = {
            'confusion_matrix': {'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn},
            'performance': {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1_score': f1_score},
            'borderline': {
                'total_count': len(borderline_cases),
                'hit_predictions': borderline_hit_pred,
                'miss_predictions': borderline_miss_pred,
                'cases': [self._simplify_case(case) for case in borderline_cases[:10]]
            }
        }
        
        print(f"ç²¾åº¦: {accuracy:.3f}, ç²¾å¯†åº¦: {precision:.3f}, å†ç¾ç‡: {recall:.3f}, F1: {f1_score:.3f}")
        print(f"BORDERLINEã‚±ãƒ¼ã‚¹: {len(borderline_cases)}ä»¶ (HITäºˆæ¸¬: {borderline_hit_pred}, MISSäºˆæ¸¬: {borderline_miss_pred})")
    
    def calculate_business_metrics(self, matched_pairs):
        """å®Ÿç”¨æ€§æŒ‡æ¨™è¨ˆç®—"""
        print("\nå®Ÿç”¨æ€§æŒ‡æ¨™è¨ˆç®—ä¸­...")
        
        metrics = self.analysis_results['binary_metrics']
        cm = metrics['confusion_matrix']
        
        total_patents = len(matched_pairs)
        predicted_hits = cm['tp'] + cm['fp'] + metrics['borderline']['hit_predictions']
        predicted_misses = cm['tn'] + cm['fn'] + metrics['borderline']['miss_predictions']
        
        manual_time_all = total_patents * 15
        system_time = predicted_hits * 10 + predicted_misses * 1
        time_saved = manual_time_all - system_time
        efficiency_gain = time_saved / manual_time_all * 100
        
        actual_hits = cm['tp'] + cm['fn']
        miss_risk = cm['fn'] / actual_hits * 100 if actual_hits > 0 else 0
        false_alarm_rate = cm['fp'] / predicted_hits * 100 if predicted_hits > 0 else 0
        
        cost_saved = (time_saved / 60) * 5000
        
        self.analysis_results['business_metrics'] = {
            'efficiency_gain_percent': efficiency_gain,
            'time_saved_minutes': time_saved,
            'cost_saved_yen': cost_saved,
            'miss_risk_percent': miss_risk,
            'false_alarm_rate_percent': false_alarm_rate
        }
        
        print(f"ä½œæ¥­åŠ¹ç‡åŒ–: {efficiency_gain:.1f}% ({time_saved:.0f}åˆ†å‰Šæ¸›)")
        print(f"ã‚³ã‚¹ãƒˆå‰Šæ¸›: {cost_saved:,.0f}å††")
        print(f"HITè¦‹é€ƒã—ãƒªã‚¹ã‚¯: {miss_risk:.1f}%")
    
    def _simplify_case(self, case):
        """ã‚±ãƒ¼ã‚¹æƒ…å ±ç°¡ç´ åŒ–"""
        return {
            'pub_number': case['pub_number'],
            'title': case['title'][:50] + '...' if len(case['title']) > 50 else case['title'],
            'pred_label': case['pred_label'],
            'confidence': round(case['confidence'], 3)
        }
    
    def generate_html_report(self):
        """HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\nHTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
        
        cm = self.analysis_results['binary_metrics']['confusion_matrix']
        perf = self.analysis_results['binary_metrics']['performance']
        biz = self.analysis_results['business_metrics']
        borderline = self.analysis_results['binary_metrics']['borderline']
        
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç‰¹è¨±äºŒå€¤åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; line-height: 1.6; margin: 0; padding: 20px; background-color: #f5f5f5; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        h1, h2 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }}
        .metrics-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(250px, 1fr)); gap: 20px; margin: 20px 0; }}
        .metric-card {{ background: #ecf0f1; padding: 20px; border-radius: 6px; text-align: center; }}
        .metric-value {{ font-size: 2em; font-weight: bold; color: #2980b9; }}
        .metric-label {{ color: #7f8c8d; font-size: 0.9em; }}
        .confusion-matrix {{ margin: 20px 0; }}
        table {{ width: 100%; border-collapse: collapse; margin: 15px 0; }}
        th, td {{ padding: 12px; text-align: center; border: 1px solid #bdc3c7; }}
        th {{ background-color: #34495e; color: white; }}
        .positive {{ color: #27ae60; font-weight: bold; }}
        .negative {{ color: #e74c3c; font-weight: bold; }}
        .warning {{ color: #f39c12; font-weight: bold; }}
        .borderline-cases {{ background: #fff3cd; padding: 15px; border-radius: 5px; margin: 15px 0; }}
        .summary {{ background: #d4edda; padding: 20px; border-radius: 5px; margin: 20px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ç‰¹è¨±äºŒå€¤åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>
        <p><strong>åˆ†ææ—¥æ™‚:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        
        <h2>ğŸ¯ ç²¾åº¦æŒ‡æ¨™</h2>
        <div class="metrics-grid">
            <div class="metric-card">
                <div class="metric-value positive">{perf['accuracy']:.1%}</div>
                <div class="metric-label">ç·åˆç²¾åº¦</div>
            </div>
            <div class="metric-card">
                <div class="metric-value positive">{perf['precision']:.1%}</div>
                <div class="metric-label">ç²¾å¯†åº¦</div>
            </div>
            <div class="metric-card">
                <div class="metric-value positive">{perf['recall']:.1%}</div>
                <div class="metric-label">å†ç¾ç‡</div>
            </div>
            <div class="metric-card">
                <div class="metric-value positive">{perf['f1_score']:.1%}</div>
                <div class="metric-label">F1ã‚¹ã‚³ã‚¢</div>
            </div>
        </div>
        
        <div class="confusion-matrix">
            <h3>æ··åŒè¡Œåˆ—</h3>
            <table>
                <thead>
                    <tr><th></th><th colspan="2">äºˆæ¸¬</th></tr>
                    <tr><th>å®Ÿéš›</th><th>HIT</th><th>MISS</th></tr>
                </thead>
                <tbody>
                    <tr><th>HIT</th><td class="positive">{cm['tp']}</td><td class="negative">{cm['fn']}</td></tr>
                    <tr><th>MISS</th><td class="warning">{cm['fp']}</td><td class="positive">{cm['tn']}</td></tr>
                </tbody>
            </table>
        </div>
        
        <h2>ğŸ’¼ å®Ÿç”¨æ€§æŒ‡æ¨™</h2>
        <div class="metrics-grid">
            <div class="metric-card">
                <div class="metric-value positive">{biz['efficiency_gain_percent']:.1f}%</div>
                <div class="metric-label">ä½œæ¥­åŠ¹ç‡åŒ–</div>
            </div>
            <div class="metric-card">
                <div class="metric-value positive">{biz['cost_saved_yen']:,.0f}å††</div>
                <div class="metric-label">ã‚³ã‚¹ãƒˆå‰Šæ¸›</div>
            </div>
            <div class="metric-card">
                <div class="metric-value {'negative' if biz['miss_risk_percent'] > 10 else 'warning'}">{biz['miss_risk_percent']:.1f}%</div>
                <div class="metric-label">HITè¦‹é€ƒã—ãƒªã‚¹ã‚¯</div>
            </div>
            <div class="metric-card">
                <div class="metric-value warning">{biz['false_alarm_rate_percent']:.1f}%</div>
                <div class="metric-label">èª¤è­¦å ±ç‡</div>
            </div>
        </div>
        
        <div class="borderline-cases">
            <h3>âš–ï¸ BORDERLINEã‚±ãƒ¼ã‚¹åˆ†æ</h3>
            <p><strong>ç·æ•°:</strong> {borderline['total_count']}ä»¶</p>
            <p><strong>HITäºˆæ¸¬:</strong> {borderline['hit_predictions']}ä»¶ | <strong>MISSäºˆæ¸¬:</strong> {borderline['miss_predictions']}ä»¶</p>
            <p>BORDERLINEã‚±ãƒ¼ã‚¹ã¯äººé–“ã«ã‚ˆã‚‹æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå¿…è¦ã§ã™ã€‚</p>
        </div>
        
        <div class="summary">
            <h3>ğŸ“Š ç·åˆè©•ä¾¡</h3>
            <p>æœ¬ã‚·ã‚¹ãƒ†ãƒ ã¯ <strong>{perf['accuracy']:.1%}</strong> ã®ç·åˆç²¾åº¦ã‚’é”æˆã—ã€
            ä½œæ¥­åŠ¹ç‡ã‚’ <strong>{biz['efficiency_gain_percent']:.1f}%</strong> å‘ä¸Šã•ã›ã€
            <strong>{biz['cost_saved_yen']:,.0f}å††</strong> ã®ã‚³ã‚¹ãƒˆå‰Šæ¸›åŠ¹æœãŒæœŸå¾…ã•ã‚Œã¾ã™ã€‚</p>
            <p>HITè¦‹é€ƒã—ãƒªã‚¹ã‚¯ã¯ <strong>{biz['miss_risk_percent']:.1f}%</strong> ã«æŠ‘åˆ¶ã•ã‚Œã¦ãŠã‚Šã€
            å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã§ã®é‹ç”¨ãŒå¯èƒ½ã§ã™ã€‚</p>
        </div>
    </div>
</body>
</html>"""
        
        report_path = Path("archive/reports/unified_analysis_report.html")
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}")
        return report_path
    
    def save_results(self):
        """çµæœä¿å­˜"""
        output_path = Path("archive/outputs/unified_analysis_results.json")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump({
                'metadata': {
                    'analysis_date': datetime.now().isoformat(),
                    'system_type': 'Binary Classification (HIT/MISS)',
                    'data_source': 'goldset (60 patents)',
                    'analysis_version': '3.0'
                },
                'results': self.analysis_results
            }, f, ensure_ascii=False, indent=2)
        
        print(f"åˆ†æçµæœä¿å­˜: {output_path}")
        return output_path
    
    def run_analysis(self):
        """çµ±åˆåˆ†æå®Ÿè¡Œ"""
        print("=" * 80)
        print("çµ±åˆç‰¹è¨±åˆ†æé–‹å§‹")
        print("=" * 80)
        
        self.load_data()
        matched_pairs = self.prepare_analysis_data()
        
        self.calculate_binary_metrics(matched_pairs)
        self.calculate_business_metrics(matched_pairs)
        
        html_report = self.generate_html_report()
        json_results = self.save_results()
        
        print("=" * 80)
        print("çµ±åˆåˆ†æå®Œäº†")
        print("=" * 80)
        
        return html_report, json_results

def main():
    analyzer = PatentAnalysis()
    html_report, json_results = analyzer.run_analysis()
    print(f"\nHTMLãƒ¬ãƒãƒ¼ãƒˆ: {html_report}")
    print(f"JSONçµæœ: {json_results}")
    return html_report, json_results

if __name__ == "__main__":
    main()